TODO

- Check the inorder / inorder-stalling-before / inorder-stalling-whole variants
  using invariants

- Check the use of store_pending rule => if current is a load
  operation and generates a cache miss in MEM stage, then what is
  required is on that no store is pending. If a store is pending, then
  the load is could jump in the memory stage and tries to generate a
  cache miss. However, this is fine to me as it will not delay the
  previous instruction ... And if a load is pending (cache miss), well
  current will be blocked. => checking absence of timing anomalies
  without this store_pending rule
  	   

- Design specific test to check that the no timing anomaly is correct
  => when fetch is already in progress (timing anomaly)
  => when transition on fetch and latency is 1 (no timing anomaly)
  => when transition on fetch and latency is > 1 (timing anomaly)

- Cleanup old models & separate per processor type

- Model K1 pipeline

- Compute maximal delay an instruction can experience

- Model branches

NOTE on the design of the abstract models

- We assume branch are removed from ID (except Patmos) or EX (Patmos)

- We assume nop instruction except for Patmos

- We model no ST stage for Patmos (because it has no ST stage)

- We assume branch generating cache misses in Patmos as being part of
  load instructions

- We do not model the data dependencies as it has nothing to do with
  timing anomalies and would only artificially increase the number of
  states (besides Patmos assumes no data dependencies, it is the job
  of the compiler ...).

- Branch behavior? Currently, we assume that the branch is not taken (fall through)
  So pipeline flush is useless ...
  => If we want to explore both branches, we should ...

RESULTS

- Demonstrate no timing anomaly for SIC: done, BMC needed is 23
- Demonstrate no timing anomaly for Patmos: done, BMC needed is 14
- Demonstrate no timing anomaly for PRET: done, BMC needed is 10
- Demonstrate timing anomalies for inorder:
  stalling before and without stalling variants => done, BMC needed is 31
  stalling whole pipeline => done, BMC needed is 33 (I was expected an higher value)


NOTES

- We were unable to model using an array of record using UCLID. Arrays
  of values works well, but we want to update a subset of an element
  of an array -> TLA+ seems better here. Similary we are unable to use
  prime value easily in a next block as we need to update a full
  variable. It is not allowed to update a field of a record for
  instance ==> one solution would be to model an instruction as a flat
  structure. This means that we have a lot of parameters to set when
  creating an instance of an instruction but that does not hurt ...

- a ST stage ensures that store accesses are performed in a asynchronous way.
  SIC paper models a write-allocate policy on write miss. No-write allocate policy
  would mean that MEM delays are ignored
  Note: If you think about the K1 processor => writes are never blocked ==>
  An infinite number of instructions can be in the ST stage => be careful for the sanity check
  For load, K1 as x loads in parallel possible, meaning that a timing anomay occurs
  if the number of instruction in MEM and IF stages is higher than x

- stores are asynchronous with the pipeline => be careful
  Write Allocate vs. No write allocate
  Write through vs. write back 
  CASE: Write back (=> in fact we cannot model this behavior by looking at the pipeline only)
  
   	and no write allocate => the write access will occur later on
   	the shared bus between instruction and data ...

	nothing
	
	and write allocate => This can potentially lead to evict data
	from the private cache (but this will occur later one) and
	load the data to be written in the cache, meaning that it is
	similar to a load operation and later on write ...

	write, load
	
  CASE: Write through => (usually assume no write allocate)

  	and no write allocate => the write access will access
  	immediately and thus request the shared bus (as the load op
  	but for a shorter amount of time as no need to wait for the
  	ack) => 

	and write allocate => a write for any potential evicted
	data, then a load, then a write

