- Changer fixed and var latencies into latencies (more generic)

- Only 2 values for latencies in order to model cache hit et miss (no
  need to have an interval) => there could be more values depending on
  whether a line a cache should be evicted before loading a new one in fact ...

- Model branch behavior for the in-order pipeline? Do we model only a
  path of a program? ==> model an assume on the current instruction
  when previous branch op has been executed in order to leave current
  in his current stage (no branch) or put it back in the pre stage (branch taken)

- Refactoring code between rules and instruction/pipeline (WiP) to avoid duplicating
  rules. In fact in the rules for a specific pipeline, we only look at instructions
  => they are not modified in those modules, only in the instruction modules
  So it migth be better to have instances of instruction in the module
  instruction in order to define generic rules in this module

- Handle delays not within each specialized pipeline (rules module)
  but instead in the instruction/pipeline module. This would avoid the
  files inorder-delays.ucl and sic-delays.ucl. But this requires a
  refactoring between rules and instruction/pipeline as the associated procedure
  requires to access to both current and previous instructions

- Specify PRET and Patmos rules

- Develop a version using prime variables for instruction module
  => cannot update a part of a record (no similar except keyword as in TLA+)
  => this means that the isa model should be flat

- Develop a version with several subsequent instructions => should be
  generated from a description of a pipeline

RESULTS

- Demonstrate no timing anomaly using LTL property for SIC initial: DONE (but bmc bound tightness has not been verified)
- Demonstrate no timing anomaly using LTL property for SIC simplified: DONE (but bmc bound tightness has not been verified)
- Demonstrate no timing anomaly using invariant property for SIC (simplified with delays):
- Compute delays for inorder pipeline:
  => This should be done for various values of latencies => but which one
- Show the equivalence between SIC initial and SIC simplified => well this is true if we do not model cache hit and cache miss
  => Demonstrate no timing anomaly using LTL property for SIC simplified:
  => Do functional equivalence and check the state and latency values for both instructions are always equal:
- Demonstrate no timing anomaly using LTL property for SIC simplified without store_pending
  => The meaning is that an unlimited number of store request can be present in ST stage 
- Demonstrate no timing anomaly using LTL property for SIC simplified with a max outstanding memory request (assume targeting different areas)
- Demonstrate no timing anomaly using LTL property for Patmos


NOTES

- The LTL property of no_timing_anomaly assume that we do not
  distinguish cache hit and misses in the pipeline rules. If we
  distinguish cache hit and misses, then current being in Fetch and
  instruction cache hit for current is fine. The property should be:
  (old_property && pipeline.previous.instr.dmiss) ==>
  (pipeline.current.instr.stage != IF && !pipeline.current.instr.stage.imiss)

- We were unable to model using an array of record using UCLID. Arrays
  of values works well, but we want to update a subset of an element
  of an array -> TLA+ seems better here. Similary we are unable to use
  prime value easily in a next block as we need to update a full
  variable. It is not allowed to update a field of a record for
  instance ==> one solution would be to model an instruction as a flat
  structure. This means that we have a lot of parameters to set when
  creating an instance of an instruction but that does not hurt ...

- a ST stage ensures that store accesses are performed in a asynchronous way.
  SIC paper models a write-allocate policy on write miss. No-write allocate policy
  would mean that MEM delays are ignored
  Note: If you think about the K1 processor => writes are never blocked ==>
  An infinite number of instructions can be in the ST stage => be careful for the sanity check
  For load, K1 as x loads in parallel possible, meaning that a timing anomay occurs
  if the number of instruction in MEM and IF stages is higher than x
